{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874baada-b757-4a4b-b973-1672b287326f",
   "metadata": {},
   "source": [
    "# User Study 02 - RL Audio Notebook\n",
    "\n",
    "Before starting this survey, please click the folliwng two links to read the explanatory statrement and answer the pre-study questionnaire.\n",
    "\n",
    "<span style=\"color:yellow\">**Explanatory Statement:**</span> https://drive.google.com/file/d/1-8npbW1wg_ABzBnnGa1dgEgCaYjDED8o/view?usp=sharing\n",
    "\n",
    "<span style=\"color:yellow\">**Pre-study Questionnaire:**</span> https://forms.gle/GAU8xzekWKkTMDLVA   (Participant ID Required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cc91e-71da-4d55-81ed-a10848f4e6a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23022b2d-e155-48ac-b0fd-8a9aa00619a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ed503-2ddc-4628-9953-8bb78dfc39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Documents/PHD/repos/RL_audio/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810beac1-8c6f-422e-92c1-2bbe9e8f6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d014-71ea-4649-a013-347682ce55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "from scripts import audio_control\n",
    "from scripts import ucb1_algorithm as ucb1\n",
    "from scripts import misc_helpers as mischelp\n",
    "\n",
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "# Termcolor guide: https://pypi.org/project/termcolor/\n",
    "\n",
    "#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#  ARGUMENTS & PARSER (Save this code for scripts working with CLI)\n",
    "\n",
    "# argParser = argparse.ArgumentParser()\n",
    "\n",
    "# # Enter any valid integer value\n",
    "# argParser.add_argument(\"-b\", \"--budg\", required=False, help=\"select the budget value (dtype=int)\")\n",
    "\n",
    "# # Enter a valid parameter discritization integer (must match sound library size)\n",
    "# argParser.add_argument(\"-d\", \"--disc\", required=False, help=\"select discritization size (dtype=int)\")\n",
    "\n",
    "# # Enter true if you would like to see hidden print log, including Q-tables\n",
    "# argParser.add_argument(\"-p\", \"--prnt\", required=False, help=\"show hidden print log (dtype=bool)\")\n",
    "\n",
    "# # To load and save, simply enter in the base filename such as \"lastsave\" or \"set_A\", system takes care of rest\n",
    "# argParser.add_argument(\"-s\", \"--save\", required=False, help=\"filename to save Q-table on exit (dtype=str)\") \n",
    "# argParser.add_argument(\"-l\", \"--load\", required=False, help=\"load Q-table from filename (dtype=str)\") \t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a1705-a32d-4cf4-88f7-9cf7a14a45bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c6de3-9aef-42ae-bb33-8a48c08c79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter discritization\n",
    "param_disc = 3 \n",
    "\n",
    "state_descriptions = [\"Stuck\t  \\t- robot needs your help\", \"Successful \\t- robot has completed it's task\", \"Progressing \\t- robot is working and doesn't need help\", \"None of the above\"]\n",
    "num_of_states = len(state_descriptions) - 1 # Adding a minus 1 since the last state in \"state_descriptions\" is \"none of the above\"\n",
    "state_range = np.arange(num_of_states)\n",
    "\n",
    "\n",
    "# CREATE SOUND LIBRARY A\n",
    "# For library A, setup the array using libA\n",
    "library_A = \"libA\"\n",
    "\n",
    "# Create an array of size (N x N x N) where N = number of discretized regions\n",
    "# number of discretized regions for each param --> i.e. if equals 3 then (0, 1, 2)\n",
    "# ** must align with the discretization for selected sound library\n",
    "sound_obj_array_A = np.ndarray((param_disc, param_disc, param_disc),dtype=object)\n",
    "\n",
    "for param_1_range in range(param_disc):\n",
    "\tfor param_2_range in range(param_disc):\n",
    "\t\tfor param_3_range in range(param_disc):\n",
    "\t\t\tsound_obj_array_A[param_1_range, param_2_range, param_3_range] = audio_control.audio_object(param_1=param_1_range, param_2=param_2_range, param_3=param_3_range, sound_library=library_A)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "# CREATE SOUND LIBRARY B\n",
    "# For library B, setup the array using libB\n",
    "library_B = \"libB\"\n",
    "\n",
    "# Create an array of size (N x N x N) where N = number of discretized regions\n",
    "# number of discretized regions for each param --> i.e. if equals 3 then (0, 1, 2)\n",
    "# ** must align with the discretization for selected sound library\n",
    "sound_obj_array_B = np.ndarray((param_disc, param_disc, param_disc),dtype=object)\n",
    "\n",
    "for param_1_range in range(param_disc):\n",
    "\tfor param_2_range in range(param_disc):\n",
    "\t\tfor param_3_range in range(param_disc):\n",
    "\t\t\tsound_obj_array_B[param_1_range, param_2_range, param_3_range] = audio_control.audio_object(param_1=param_1_range, param_2=param_2_range, param_3=param_3_range, sound_library=library_B)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567c300-989f-40c8-b1be-69510f22ccab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MAIN STUDY\n",
    "\n",
    "Welcome to this study's <span style=\"color:yellow\">**Jupyter notebook**</span>. In this work, we are developing strategies for improving human-robot interaction with nonverbal sounds (<span style=\"color:yellow\">**_beeps & boops_**</span>).\n",
    "\n",
    "While a robot is working on a task, it can have many different internal states... \n",
    "\n",
    "If the robot gets stuck behind an obstacle, the robot's internal state is: <span style=\"color:Red\">**Stuck**</span>\n",
    "\n",
    "Similarly, if the robot was able to reach it's goal, the robot's internal state is: <span style=\"color:green\">**Successful**</span>\n",
    "\n",
    "If the robot is actively working on the task but has neither gotten stuck nor completed the task, the robot's internal state is: <span style=\"color:blue\">**Progressing**</span>\n",
    "\n",
    "In this notebook, you will be asked to run through <span style=\"color:yellow\">**3 sections**</span>. In each of these sections, a virtual robot will play a sound. Once you listen to the sound, you will be asked to select which robot state you think the virtual robot is in. You will have the options: <span style=\"color:Red\">**Stuck**</span>, <span style=\"color:green\">**Successful**</span>, <span style=\"color:blue\">**Progressing**</span> and <span style=\"color:purple\">**Not Sure**</span>\n",
    "\n",
    "In addition to each answer, you will also self-score how confident you are in your response, on a scale from 1 to 10. \n",
    "\n",
    "This process will repeat several times as a learning algorithm is processing in the background. <span style=\"color:yellow\">**If you have any questions, simply ask your study moderator**</span>. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecda1d0-d6cb-45e9-b2f2-158709277330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SECTION 1\n",
    "\n",
    "Start by entering your user ID. \n",
    "\t\n",
    "<span style=\"color:yellow\">**Click on the first cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f50b0a-b88d-4d55-a9e8-dfd8e7bd1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user_ID_str = mischelp.get_user_ID(parent_dir=PWD, num_of_states=num_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b7585-4d7b-4110-bf9e-a9a98157462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_A, lib_str=library_A, sect_str=\"sect1\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, states_array=np.ndarray(num_of_states, dtype=object), \n",
    "\t\t\t\t\t  state_descriptions=state_descriptions, param_disc=param_disc, load_file=\"pilotset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522dad9-f3fc-45c4-871c-39035dd2234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_B, lib_str=library_B, sect_str=\"sect1\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, states_array=np.ndarray(num_of_states, dtype=object), \n",
    "\t\t\t\t\t  state_descriptions=state_descriptions, param_disc=param_disc, load_file=\"pilotset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ca2de-78ed-4687-80e7-3b81400b4072",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50631102-91eb-45e8-b7e9-f58f59cc15c1",
   "metadata": {},
   "source": [
    "### Section 2X\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the first cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f87f4c-e025-4172-ae7d-16394478c344",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 2O\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the first cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b20e8c-adf6-493d-8600-09997b176a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations:\n",
    "time_step = 0\t \t\t# Initialize time_step to zero\n",
    "budget = 50\t   \t\t\t# Max number of total iterations \n",
    "\n",
    "save_file = current_user_ID_str + \"_sect2O\"\t# Filename to save Q-table on exit\n",
    "load_file = None  \t\t                    # No loadfile sets matrix to flat (change this to \"pilotset\" for other)\n",
    "\n",
    "printer = True\t\t\t# Either set to True or None (prints hidden statements for debug)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize to center of mapping\n",
    "param_1_idx = 1 \n",
    "param_2_idx = 1\n",
    "param_3_idx = 1\n",
    "\n",
    "\n",
    "# Re-Initialize states array. Each state is initialized with a Q-table based on load_file\n",
    "states_array = np.ndarray(num_of_states, dtype=object)\n",
    "for state_idx in range(num_of_states):\n",
    "\tstates_array[state_idx] = ucb1.robot_state(state_idx=state_idx, description=state_descriptions[state_idx], param_disc=param_disc, \n",
    "\t\t\t\t\t\t\t\t\t\t\t   load_file=load_file, user_ID_str=current_user_ID_str)\n",
    "\n",
    "\t\n",
    "for i in range(0, budget):\n",
    "\t\n",
    "\tcurrent_state_index = np.random.randint(0, 3) \t\t# Current actual state of the robot - change this to fluctuate during study\n",
    "\n",
    "\tif time_step == 0 and load_file == None:\n",
    "\t\tparam_1_idx = 1 \n",
    "\t\tparam_2_idx = 1\n",
    "\t\tparam_3_idx = 1\n",
    "\telse:\n",
    "\t# Select new params\n",
    "\t\tparam_1_idx, param_2_idx, param_3_idx = states_array[current_state_index].action_selection()\n",
    "\n",
    "\ttime_step_str = f\"{time_step:02}\"\n",
    "    print(f\"Time Step: {time_step_str}\"\n",
    "\ttime_step += 1\n",
    "\t\n",
    "\tprint(\"\\n----------------------------------------------------------------\")\n",
    "\tprint(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\tprint(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "\tif printer:\n",
    "\t\tprint(\"(Hidden):\")\n",
    "\t\tprint(f\"Current actual state of robot: {current_state_index}\\n\")\n",
    "\t\tprint(f\"New Param INDICES (not direct values): \\nP1: {param_1_idx} (Beats per Minute - BPM) \\nP2: {param_2_idx} (Beeps per Loop - BPL) \\nP3: {param_3_idx} (Amplitude of Pitch Change)\\n\")\n",
    "\n",
    "\n",
    "\t# Play the desired mp3 file, probe user based on sound, then update the Q-Value look-up table...\n",
    "\n",
    "\t# Probe user for perceived state & confidence in their response\n",
    "\tprobed_state_index, probed_confidence = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].probe(state_descriptions)\n",
    "\n",
    "\t# Update N for audio obj\n",
    "\tsound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].update()\n",
    "\n",
    "\t# Calculate uncertainty signal (U_t) based on N and time_step\n",
    "\tuncertainty_signal = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].uncertainty(time_step)\n",
    "\n",
    "\t# For each state, calculate the respective reward signal (R)\n",
    "\tfor state_idx in range(num_of_states):\n",
    "\n",
    "\t\tif probed_state_index == len(state_descriptions) - 1:\n",
    "\t\t\treward_signal = 0.0\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tif probed_state_index == state_idx:\n",
    "\t\t\t\tcorrect_multiplier = 1.0\n",
    "\t\t\telif probed_state_index != state_idx:\n",
    "\t\t\t\tcorrect_multiplier = -1.0\n",
    "\n",
    "\t\t\t# This is the reward signal R\n",
    "\t\t\treward_signal = correct_multiplier * probed_confidence\n",
    "\n",
    "\t\t# Calculate new Q_t = {[(1 - 1/n) * Q_t-1] + [(1/n) * R]} + U_t   ~  UCB1 algorithm update equation\n",
    "\t\t# Takes the mean of previously observed reward and new reward, adding on an uncertainty term\n",
    "\t\tQ_value = ((1 - 1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * states_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] + (1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * reward_signal) + uncertainty_signal\n",
    "\n",
    "\t\t# Update value in lookup table for state S with new Q_t\n",
    "\t\t# Added an np.clip so that the mix/max Q-Value in the table cant exceed -10 to +10\n",
    "\t\tstates_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] = np.clip(Q_value, -10, 10)\n",
    "\n",
    "\t\tif printer:\n",
    "\t\t\tprint(\"\\n\\n----------------------------------------------------------------\\n\")\n",
    "\t\t\tprint(\"(Hidden):\")\n",
    "\t\t\tprint(f\"Uncertainty_signal (U):\\t {uncertainty_signal}\")\n",
    "\t\t\tprint(f\"Reward_signal (R):\\t {reward_signal}\")\n",
    "\t\t\tprint(f\"New action value (Q):\\t {Q_value}\")\n",
    "\t\t\tprint(f\"Q-table after update for state {state_idx}:\\n\")\n",
    "\t\t\tprint(states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\t\n",
    "\t\tnp.save(\"user_data/user_\" + current_user_ID_str + \"/arrays/\" + save_file + \"_step\" + time_step_str + \"_st\" + str(state_idx) + \".npy\", states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\ttime.sleep(1) # Put here to make UI a bit nicer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b267ad4-05ec-4b7a-b79f-bc76eae24fad",
   "metadata": {},
   "source": [
    "## Closing Survey\n",
    "\n",
    "Thank you for completing this Jupyter Notebook. Please click the folliwng link to answer a short post-study questionnaire.\n",
    "\n",
    "<span style=\"color:yellow\">**Pre-study Questionnaire:**</span> https://forms.gle/K6RnncY82vSVdyE38   (Participant ID Required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945efb78-e5e6-41b1-ba89-25c1fe7b37ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NOTES & DEBUG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1b772-d31a-4608-8b21-a740dcf7859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b316ea7-20ff-43e7-8d6d-f167239a42b6",
   "metadata": {},
   "source": [
    "Creating buttons and widgets: https://medium.com/@technologger/how-to-interact-with-jupyter-33a98686f24e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
